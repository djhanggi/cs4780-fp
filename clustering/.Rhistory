# Linear Regression
#
#
# This follows from McCarthy, M. A. 2007 Bayesian Methods for Ecology
# R code Box 5.2
#
#
my.data = list(
TreeDens=c(1270,1210,1800,1875,1300,2150,1330,964,961,1400,1280,976,771,833,883,956),
CWD=c(121,41,183,130,127,134,65,52,12,46,54,97,1,4,1,4) )
#
# Plot Data
#
plot(my.data$TreeDens,my.data$CWD,xlab="Tree Density",ylab="CWD")
title("Coarse Woody Debris vs. Tree Density")
#
#
# Conduct a simple linear regression
#
cwd.lm = lm (CWD~TreeDens,data=my.data)
#
# Add the regression line to the plot
#
abline(coef(cwd.lm),col=2,lwd=3)
#
#
newdata = list(TreeDens=seq(800,2200))
cwd.pred = predict(cwd.lm,newdata=newdata,se.fit=T)
lowerCI = cwd.pred$fit - 2 * cwd.pred$se.fit
upperCI = cwd.pred$fit + 2 * cwd.pred$se.fit
lines(newdata$TreeDens,cwd.pred$fit)
lines(newdata$TreeDens,lowerCI,col=3)
lines(newdata$TreeDens,upperCI,col=3)
#
#
#
# Examine the estimates and standard errors of the coefficients
#
summary(cwd.lm)
#
#
# Create a new point for prediction
#
newdata = list(TreeDens=1500)
#
# Save the prediction as my.pred
#
my.pred = predict(cwd.lm,newdata=newdata,se.fit=T)
my.pred
#
# Compute the Mean Squared Error from the linear model
#
MSE = sum(resid(cwd.lm)^2)/df.residual(cwd.lm)
MSE
#
# The standard error for a new observation
#
se.ynew = sqrt(MSE+my.pred$se.fit^2)
se.ynew
#
# Sparrow data analysis
# Sullivan
#
# Change to working directory where data is stored
# e.g.
#  setwd("C:\\Users\\pjs31\\Documents\\Cornell\\NTRES 4130.14\\Data")
#
# Read in data
#
#
sparrow = data.frame(
age.days=c(3,4,5,6,8,9,10,11,12,14,15,16,17),
wing.length=
c(1.4,1.5,2.2,2.4,3.1,3.2,3.2,
3.9,4.1,4.7,4.5,5.2,5.0))
head(sparrow)
#
#
# Plot the data to see what it looks like
# (two methods)
#
plot(wing.length~age.days,data=sparrow,pch=15)
#
plot(sparrow$age.days,sparrow$wing.length,pch=15)
#
#
# Conduct a linear regression of sparrow wing.length against age.days
# (two methods)
#
# Standard linear model with Gaussian distribution assumption
#
sparrow.lm = lm(wing.length~age.days,data=sparrow)
#
#
# Generalized linear model (can be used with other distributions, later in the semester)
#
sparrow.glm = glm(wing.length~age.days,data=sparrow)
#
#
# Compare output summaries
#
summary(sparrow.lm)
summary(sparrow.glm)
#
# Is the slope signficantly different from zero?
# Check to see t-value is above critical value.
# Also, check that p-value is smaller than 0.05 say
#
# Another summary of the data is through an ANOVA type table
#
anova(sparrow.lm)
#
# The can be found in this table as the Mean Sq of the Residuals
#
# or it can be computed directly as
#
sum(resid(sparrow.lm)^2)/11
#
# 0.04770085
#
# or as
#
beta0 = coef(sparrow.lm)[1]
beta1 = coef(sparrow.lm)[2]
#
MSE = sum((sparrow$wing.length - (beta0 + beta1 * sparrow$age.days))^2)/(length(sparrow$age.days) - 2)
MSE
#
#
#
# Test for Gaussian distribution assumptions using
# normal probability plots also known as quantile plots
#
qqnorm(resid(sparrow.lm),pch=15)
qqline(resid(sparrow.lm))
#
#
#
# Make predictions of the mean with standard error
# at prescribed data points
#
sparrow.newpoints = data.frame(age.days=seq(3,17))
#
sparrow.predict = predict(sparrow.lm,se.fit=T,newdata=sparrow.newpoints)
#
#
# Plot just the predictions first as points
#
plot(sparrow.newpoints$age.days, sparrow.predict$fit, pch=15)
#
#
# Now plot as line with 95% confidence envelope included
#
# First set up the plot, by plotting without including points
#
plot(sparrow.newpoints$age.days, sparrow.predict$fit,type="n",
xlab="Age (days)",ylab="Predicted Wing Length (inches)")
#
# then include a line based on the predicted points, lwd determines line width
#
lines(sparrow.newpoints$age.days, sparrow.predict$fit,lwd=3)
#
# create what is needed to make the envelope, mean +/- 2 se
#
sparrow.upper = sparrow.predict$fit+2*sparrow.predict$se.fit
sparrow.lower = sparrow.predict$fit-2*sparrow.predict$se.fit
#
# plot the two envelope lines in a different color
#
lines(sparrow.newpoints$age.days, sparrow.upper, col=2, lwd=3)
lines(sparrow.newpoints$age.days, sparrow.lower, col=2, lwd=3)
#
# add a title
#
title("Predicted Wing Length")
#
#
# Add bootstraped lines
#
for(i in seq(100)) abline(coef(lm(wing.length~age.days,data=sparrow[sample(dim(sparrow)[1],replace=T),])))
#
# Add Confidence Intervals on top
#
lines(sparrow.newpoints$age.days, sparrow.upper, col=2, lwd=3)
lines(sparrow.newpoints$age.days, sparrow.lower, col=2, lwd=3)
#
###############
#
# Now some additional commands
#
#
# To make a prediction for one point,
# for example what is the wing length for a bird at age 12
#
sparrow.predict.12 = predict(sparrow.lm,newdata=data.frame(age.days=12),se.fit=T)
#
#
# For the confidence interval for a new observation:
#
# You get the estimate from the prediction above and
# calculate the standard error for the new observation as follows:
#
s2.yh.new.sparrow = MSE + sparrow.predict.12$se.fit^2
#
# standard error of new prediction
#
s.yh.new.sparrow = sqrt(s2.yh.new.sparrow)
#
# Confidence interval for wing length of new sparrow of age 12
#
sparrow.predict.12$fit + c(-2,2) * s.yh.new.sparrow
#
#################
#
# Obtain a 99 percent confidence interval for the slope:
#
#
sparrow.sample.size = length(sparrow$wing.length)
#
# Notice that we usually use plus or minus 2 standard errors, which corresponds to the following t critical value:
#
qt(.975,sparrow.sample.size-2)
#
# Here however, we are looking for alpha = 0.01, or 1-alpha/2 = 0.995, so
#
qt(.995,sparrow.sample.size-2)
#
# The confidence interval can be found using beta1 +/- t(1-alpha/2) SE, so
# Note that the estimate 0.2702 and se 0.0135 come from summary(sparrow.lm)
#
0.2702 + c(-1, 1) * qt(0.995, sparrow.sample.size-2) * 0.0135
#
#
#
plot(index~days,data=prognostic)
n = length(prognostic$days)
id = seq(n)
boot.coef = coef(prognostic.nls)  # Save original estimates
for(i in seq(100))
{
id.boot = sample(id,replace=T)
boot.data = list(
days = prognostic$days,
index = predict(prognostic.nls)+
resid(prognostic.nls)[id.boot])
prognostic.start = list(g0 = 55, g1 =-0.05)
boot.nls = nls(index~g0*exp(g1*days),
start=prognostic.start,
data=boot.data)
boot.coef = rbind(boot.coef,coef(boot.nls))
boot.fit = predict(boot.nls,
newdata=prognostic)
lines(prognostic $days,boot.fit,lwd=3,col=5)
}
lines(prognostic$days,predict(prognostic.nls),
lwd=2,col=2)
lines(prognostic$days,
predict(prognostic.nls)+2*se.fit,lwd=2,col=3)
lines(prognostic$days,
predict(prognostic.nls)-2*se.fit,lwd=2,col=3)
sparrow = data.frame(
age.days=c(3,4,5,6,8,9,10,11,12,14,15,16,17),
wing.length=
c(1.4,1.5,2.2,2.4,3.1,3.2,3.2,
3.9,4.1,4.7,4.5,5.2,5.0))
head(sparrow)
plot(wing.length~age.days,data=sparrow,pch=15)
#
plot(sparrow$age.days,sparrow$wing.length,pch=15)
sparrow.lm = lm(wing.length~age.days,data=sparrow)
#
beta0 = coef(sparrow.lm)[1]
beta1 = coef(sparrow.lm)[2]
#
MSE = sum((sparrow$wing.length - (beta0 + beta1 * sparrow$age.days))^2)/(length(sparrow$age.days) - 2)
MSE
sparrow.newpoints = data.frame(age.days=seq(3,17))
#
sparrow.predict = predict(sparrow.lm,se.fit=T,newdata=sparrow.newpoints)
#
#
# Plot just the predictions first as points
#
plot(sparrow.newpoints$age.days, sparrow.predict$fit, pch=15)
#
plot(sparrow.newpoints$age.days, sparrow.predict$fit,type="n",
xlab="Age (days)",ylab="Predicted Wing Length (inches)")
#
lines(sparrow.newpoints$age.days, sparrow.predict$fit,lwd=3)
#
# create what is needed to make the envelope, mean +/- 2 se
sparrow.upper = sparrow.predict$fit+2*sparrow.predict$se.fit
sparrow.lower = sparrow.predict$fit-2*sparrow.predict$se.fit
lines(sparrow.newpoints$age.days, sparrow.upper, col=2, lwd=3)
lines(sparrow.newpoints$age.days, sparrow.lower, col=2, lwd=3)
#
con <- url("http://www.jhsph.edu", "r")
con
help(url)
type(con)
class(con)
x = readLines(con)
class(x)
x
con <- url("http://jhsph.edu", "r")
x = readLines(con)
head(x)
ucscDb = dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
help(dbConnect)
install.package(dbConnect)
package(dbConnect)
library(dbConnect)
library(RMySQL)
library("RMySQL")
getwd()
setwd("Desktop/OneDrive/Documents/DATA_SCIENCE")
setwd("/Desktop/OneDrive/Documents/DATA_SCIENCE")
setwd("/Desktop/OneDrive/Documents/DATA_SCIENCE/")
setwd("./Desktop/OneDrive/Documents/DATA_SCIENCE/")
setwd("Users/VeenaCalambur/Desktop/OneDrive/Documents/DATA_SCIENCE/")
install.packages("RMySQL")
library(RMySQL)
ucscDB = dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
result = dbGetQuery(ucscDB, "show databases;"); dbDisconnect(ucscDB);
result
ucscDB = dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu", db = "hg19")
allTables = dbListTables(hg19)
allTables = dbListTables(ucscDB)
length(allTables)
allTables[1:5]
dbListFields(ucscDB, "affyU133Plus2")
dbGetQuery(ucscDB, "select count(*) from affyU133Plus2")
affyData = dbReadTable (ucscDB, "affyU133Plus2")
head(affyData)
library(ElemStatLearn)
install.package(ElemStatLearn)
install.packages(ElemStatLearn)
library(ElemStatLearn)
libarary("ElemStatLearn")
library("ElemStatLearn")
install.packages("ElemStatLearn")
library("ElemStatLearn")
require(class)
x = (0,2,4, 2, 5, 6)
xposR = (0, 2, 4)
xposR = list(0, 2 4)
xposR = c(0, 2, 4)
yposR = c(1, 3, 4)
xposC = c(2, 5, 6)
yposC = c(0, 2, 3)
head(mixture.example$x)
col.names(mixture)
names(mixture)
names(mixture.example)
library(ggplot2)
qf(0.025, 64, 80)
qf(0.05, 64, 80)
If any two feature vectors are orthogonal, then we can reduce the dual optimization equation because any values of $i \neq j$ will reduce the inner product between the features to 0, And the inner product from i = j, will be the length of that particular feature, which has also been set to 1:
D(\alpha) = \sum\limits_{i = 1}^{N}\alpha_{i} - \frac{1}{2}\sum\limits_{i = 1}^{N}\sum\limits_{j = 1}^{N}y_{i}y_{j}\alpha_{i}\alpha_{j}x_{i}x_{j}
source('~/.active-rstudio-document')
c1 = c("Electronic", "
Soundtrack", "
Electronic", "
Rock", "
Rock", "
Jazz", "
Classical", "
Jazz", "
Alternative", "New Age
Classical", "
Rock", "
Rock", "
Pop", "
Vocal", "
Classical", "
Electronic", "
Soundtrack", "
Rock", "
Soundtrack", "
Holiday", "
Rock")
setwd("~/Desktop/CS478final/clustering")
a = read.table("classifications.txt", sep = "\t")
a = read.table("classifications.txt", sep = "\t", header = TRUE)
head(a)
a = read.table("classifications.txt", sep = "\t", header = TRUE)
cluster1 = subset(a, Cluster == "C1")
cluster1
for i in (1:length(cluster1$Genre)){
print (sapply(cluster1$Genre, function(x)sum(grepl(cluster1$Genre[i], x))))
}
for i in (1:length(cluster1$Genre)){
print (sapply(cluster1$Genre, function(x){sum(grepl(cluster1$Genre[i], x))}))
}
for (i in (1:length(cluster1$Genre))){
print (sapply(cluster1$Genre, function(x){sum(grepl(cluster1$Genre[i], x))}))
}
for (i in (1:length(cluster1$Genre))){
sapply(cluster1$Genre, function(x){sum(grepl(cluster1$Genre[i], x))})
}
t = 0
for (i in (1:length(cluster1$Genre))){
t = t + sapply(cluster1$Genre, function(x){sum(grepl(cluster1$Genre[i], x))})
}
t
cluster1$Genre
length(t)
source('~/.active-rstudio-document')
cluster1 = subset(a, Cluster == "C1")
cluster2 = subset(a, Cluster == "C2")
cluster3 = subset(a, Cluster == "C3")
cluster4 = subset(a, Cluster == "C4")
cluster5 = subset(a, Cluster == "C5")
cluster6 = subset(a, Cluster == "C6")
cluster7 = subset(a, Cluster == "C7")
cluster8 = subset(a, Cluster == "C8")
cluster9 = subset(a, Cluster == "C9")
c1t = 0
for (i in (1:length(cluster1$Genre))){
c1t = c1t + sapply(cluster1$Genre, function(x){sum(grepl(cluster1$Genre[i], x))})
}
c2t = 0
for (i in (1:length(cluster2$Genre))){
c2t = c2t + sapply(cluster2$Genre, function(x){sum(grepl(cluster2$Genre[i], x))})
}
c3t = 0
for (i in (1:length(cluster3$Genre))){
c3t = c3t + sapply(cluster2$Genre, function(x){sum(grepl(cluster3$Genre[i], x))})
}
c4t = 0
for (i in (1:length(cluster4$Genre))){
c4t = c4t + sapply(cluster4$Genre, function(x){sum(grepl(cluster4$Genre[i], x))})
}
c5t = 0
for (i in (1:length(cluster5$Genre))){
c5t = c5t + sapply(cluster5$Genre, function(x){sum(grepl(cluster5$Genre[i], x))})
}
c6t = 0
for (i in (1:length(cluster6$Genre))){
c6t = c6t + sapply(cluster6$Genre, function(x){sum(grepl(cluster6$Genre[i], x))})
}
c7t = 0
for (i in (1:length(cluster7$Genre))){
c7t = c7t + sapply(cluster7$Genre, function(x){sum(grepl(cluster7$Genre[i], x))})
}
c8t = 0
for (i in (1:length(cluster8$Genre))){
c8t = c8t + sapply(cluster8$Genre, function(x){sum(grepl(cluster8$Genre[i], x))})
}
c9t = 0
for (i in (1:length(cluster9$Genre))){
c9t = c9t + sapply(cluster9$Genre, function(x){sum(grepl(cluster9$Genre[i], x))})
}
c1t; cluster1$Genre
c1t[14]
c1t[15]
c1t[13]
c1t[9]
list(c1t, cluster1$Genre)
help(list)
test = list(c(ct1, cluster1$Genre))
test = list(c(c1t, cluster1$Genre))
test
test = vector(c1t, cluster1$Genre)
length(c1t)
length(cluster1$Genre)
test = list(c1t, cluster1$Genre)
test[1]
test = as.list(setNames(c1t, cluster1$Genre))
test
c2 = as.list(setNames(c2t, cluster2$Genre))
c2[1]
c2[0]
c2[2]
c2[3]
c2
c3 = as.list(setNames(c3t, cluster3$Genre))
c3t = 0
for (i in (1:length(cluster3$Genre))){
c3t = c3t + sapply(cluster2$Genre, function(x){sum(grepl(cluster3$Genre[i], x))})
}
c3 = as.list(setNames(c3t, cluster3$Genre))
c3t = 0
for (i in (1:length(cluster3$Genre))){
c3t = c3t + sapply(cluster3$Genre, function(x){sum(grepl(cluster3$Genre[i], x))})
}
c3 = as.list(setNames(c3t, cluster3$Genre))
c3
c4 = as.list(setNames(c4t, cluster4$Genre))
c4
length(c2)
length(c3)
length(c4)
c5 = as.list(setNames(c5t, cluster5$Genre))
c5
c6 = as.list(setNames(c6t, cluster6$Genre))
c6
c6t = 0
for (i in (1:length(cluster6$Genre))){
c6t = c6t + sapply(cluster6$Genre, function(x){sum(grepl(cluster6$Genre[i], x))})
}
c6 = as.list(setNames(c6t, cluster6$Genre))
c6
c7 = as.list(setNames(c7t, cluster7$Genre))
c7
c8 = as.list(setNames(c8t, cluster8$Genre))
c8
c8["Relaxation"]
c8["New Age"]
c8["Alternative"]
c9 = as.list(setNames(c9t, cluster9$Genre))
c9
