#
parameters = c("a","b","prec")
#
# Run MCMC for model
#
Regression.sim = bugs(my.data,inits,parameters,"BayesReg.bug",
n.chains=2,n.iter=10000,program="OpenBUGS")
#
# Examine summary output
#
print(Regression.sim)
#
# Plot chains for slope term
#
id = seq(length(Regression.sim$sims.array[,1,"b"]))
plot(id, Regression.sim$sims.array[,1,"b"],type="l")
lines(id,Regression.sim$sims.array[,2,"b"],col=2)
#
# Distribution of slope term
hist(Regression.sim$sims.array[,1,"b"])
#
#
# Estimates
#
mean(Regression.sim$sims.array[,1,"a"])
sqrt(var( Regression.sim$sims.array[,1,"a"]))
mean(Regression.sim$sims.array[,1,"b"])
sqrt(var( Regression.sim$sims.array[,1,"b"]))
mean(Regression.sim$sims.array[,1,"prec"])
sqrt(var( Regression.sim$sims.array[,1,"prec"]))
#
#
# Regression line with 95% Confidence (Bayesian Credible) Interval
#
plot(CWD~TreeDens,data=my.data)
#
x = seq(800,2200)
y = NULL
a = Regression.sim$sims.array[,1,"a"]
b = Regression.sim$sims.array[,1,"b"]
for(i in seq(length(a))) y = rbind(y,a[i]+b[i]*x)
y.upper = apply(y,2,quantile,.975)
y.lower = apply(y,2,quantile,.025)
y.median = apply(y,2,quantile,.5)
lines(x,y.upper,col="green")
lines(x,y.lower,col="green")
lines(x,y.median,col="red")
# Linear Regression
#
#
# This follows from McCarthy, M. A. 2007 Bayesian Methods for Ecology
# R code Box 5.2
#
#
my.data = list(
TreeDens=c(1270,1210,1800,1875,1300,2150,1330,964,961,1400,1280,976,771,833,883,956),
CWD=c(121,41,183,130,127,134,65,52,12,46,54,97,1,4,1,4) )
#
# Plot Data
#
plot(my.data$TreeDens,my.data$CWD,xlab="Tree Density",ylab="CWD")
title("Coarse Woody Debris vs. Tree Density")
#
#
# Conduct a simple linear regression
#
cwd.lm = lm (CWD~TreeDens,data=my.data)
#
# Add the regression line to the plot
#
abline(coef(cwd.lm),col=2,lwd=3)
#
#
newdata = list(TreeDens=seq(800,2200))
cwd.pred = predict(cwd.lm,newdata=newdata,se.fit=T)
lowerCI = cwd.pred$fit - 2 * cwd.pred$se.fit
upperCI = cwd.pred$fit + 2 * cwd.pred$se.fit
lines(newdata$TreeDens,cwd.pred$fit)
lines(newdata$TreeDens,lowerCI,col=3)
lines(newdata$TreeDens,upperCI,col=3)
#
#
#
# Examine the estimates and standard errors of the coefficients
#
summary(cwd.lm)
#
#
# Create a new point for prediction
#
newdata = list(TreeDens=1500)
#
# Save the prediction as my.pred
#
my.pred = predict(cwd.lm,newdata=newdata,se.fit=T)
my.pred
#
# Compute the Mean Squared Error from the linear model
#
MSE = sum(resid(cwd.lm)^2)/df.residual(cwd.lm)
MSE
#
# The standard error for a new observation
#
se.ynew = sqrt(MSE+my.pred$se.fit^2)
se.ynew
#
# Sparrow data analysis
# Sullivan
#
# Change to working directory where data is stored
# e.g.
#  setwd("C:\\Users\\pjs31\\Documents\\Cornell\\NTRES 4130.14\\Data")
#
# Read in data
#
#
sparrow = data.frame(
age.days=c(3,4,5,6,8,9,10,11,12,14,15,16,17),
wing.length=
c(1.4,1.5,2.2,2.4,3.1,3.2,3.2,
3.9,4.1,4.7,4.5,5.2,5.0))
head(sparrow)
#
#
# Plot the data to see what it looks like
# (two methods)
#
plot(wing.length~age.days,data=sparrow,pch=15)
#
plot(sparrow$age.days,sparrow$wing.length,pch=15)
#
#
# Conduct a linear regression of sparrow wing.length against age.days
# (two methods)
#
# Standard linear model with Gaussian distribution assumption
#
sparrow.lm = lm(wing.length~age.days,data=sparrow)
#
#
# Generalized linear model (can be used with other distributions, later in the semester)
#
sparrow.glm = glm(wing.length~age.days,data=sparrow)
#
#
# Compare output summaries
#
summary(sparrow.lm)
summary(sparrow.glm)
#
# Is the slope signficantly different from zero?
# Check to see t-value is above critical value.
# Also, check that p-value is smaller than 0.05 say
#
# Another summary of the data is through an ANOVA type table
#
anova(sparrow.lm)
#
# The can be found in this table as the Mean Sq of the Residuals
#
# or it can be computed directly as
#
sum(resid(sparrow.lm)^2)/11
#
# 0.04770085
#
# or as
#
beta0 = coef(sparrow.lm)[1]
beta1 = coef(sparrow.lm)[2]
#
MSE = sum((sparrow$wing.length - (beta0 + beta1 * sparrow$age.days))^2)/(length(sparrow$age.days) - 2)
MSE
#
#
#
# Test for Gaussian distribution assumptions using
# normal probability plots also known as quantile plots
#
qqnorm(resid(sparrow.lm),pch=15)
qqline(resid(sparrow.lm))
#
#
#
# Make predictions of the mean with standard error
# at prescribed data points
#
sparrow.newpoints = data.frame(age.days=seq(3,17))
#
sparrow.predict = predict(sparrow.lm,se.fit=T,newdata=sparrow.newpoints)
#
#
# Plot just the predictions first as points
#
plot(sparrow.newpoints$age.days, sparrow.predict$fit, pch=15)
#
#
# Now plot as line with 95% confidence envelope included
#
# First set up the plot, by plotting without including points
#
plot(sparrow.newpoints$age.days, sparrow.predict$fit,type="n",
xlab="Age (days)",ylab="Predicted Wing Length (inches)")
#
# then include a line based on the predicted points, lwd determines line width
#
lines(sparrow.newpoints$age.days, sparrow.predict$fit,lwd=3)
#
# create what is needed to make the envelope, mean +/- 2 se
#
sparrow.upper = sparrow.predict$fit+2*sparrow.predict$se.fit
sparrow.lower = sparrow.predict$fit-2*sparrow.predict$se.fit
#
# plot the two envelope lines in a different color
#
lines(sparrow.newpoints$age.days, sparrow.upper, col=2, lwd=3)
lines(sparrow.newpoints$age.days, sparrow.lower, col=2, lwd=3)
#
# add a title
#
title("Predicted Wing Length")
#
#
# Add bootstraped lines
#
for(i in seq(100)) abline(coef(lm(wing.length~age.days,data=sparrow[sample(dim(sparrow)[1],replace=T),])))
#
# Add Confidence Intervals on top
#
lines(sparrow.newpoints$age.days, sparrow.upper, col=2, lwd=3)
lines(sparrow.newpoints$age.days, sparrow.lower, col=2, lwd=3)
#
###############
#
# Now some additional commands
#
#
# To make a prediction for one point,
# for example what is the wing length for a bird at age 12
#
sparrow.predict.12 = predict(sparrow.lm,newdata=data.frame(age.days=12),se.fit=T)
#
#
# For the confidence interval for a new observation:
#
# You get the estimate from the prediction above and
# calculate the standard error for the new observation as follows:
#
s2.yh.new.sparrow = MSE + sparrow.predict.12$se.fit^2
#
# standard error of new prediction
#
s.yh.new.sparrow = sqrt(s2.yh.new.sparrow)
#
# Confidence interval for wing length of new sparrow of age 12
#
sparrow.predict.12$fit + c(-2,2) * s.yh.new.sparrow
#
#################
#
# Obtain a 99 percent confidence interval for the slope:
#
#
sparrow.sample.size = length(sparrow$wing.length)
#
# Notice that we usually use plus or minus 2 standard errors, which corresponds to the following t critical value:
#
qt(.975,sparrow.sample.size-2)
#
# Here however, we are looking for alpha = 0.01, or 1-alpha/2 = 0.995, so
#
qt(.995,sparrow.sample.size-2)
#
# The confidence interval can be found using beta1 +/- t(1-alpha/2) SE, so
# Note that the estimate 0.2702 and se 0.0135 come from summary(sparrow.lm)
#
0.2702 + c(-1, 1) * qt(0.995, sparrow.sample.size-2) * 0.0135
#
#
#
plot(index~days,data=prognostic)
n = length(prognostic$days)
id = seq(n)
boot.coef = coef(prognostic.nls)  # Save original estimates
for(i in seq(100))
{
id.boot = sample(id,replace=T)
boot.data = list(
days = prognostic$days,
index = predict(prognostic.nls)+
resid(prognostic.nls)[id.boot])
prognostic.start = list(g0 = 55, g1 =-0.05)
boot.nls = nls(index~g0*exp(g1*days),
start=prognostic.start,
data=boot.data)
boot.coef = rbind(boot.coef,coef(boot.nls))
boot.fit = predict(boot.nls,
newdata=prognostic)
lines(prognostic $days,boot.fit,lwd=3,col=5)
}
lines(prognostic$days,predict(prognostic.nls),
lwd=2,col=2)
lines(prognostic$days,
predict(prognostic.nls)+2*se.fit,lwd=2,col=3)
lines(prognostic$days,
predict(prognostic.nls)-2*se.fit,lwd=2,col=3)
sparrow = data.frame(
age.days=c(3,4,5,6,8,9,10,11,12,14,15,16,17),
wing.length=
c(1.4,1.5,2.2,2.4,3.1,3.2,3.2,
3.9,4.1,4.7,4.5,5.2,5.0))
head(sparrow)
plot(wing.length~age.days,data=sparrow,pch=15)
#
plot(sparrow$age.days,sparrow$wing.length,pch=15)
sparrow.lm = lm(wing.length~age.days,data=sparrow)
#
beta0 = coef(sparrow.lm)[1]
beta1 = coef(sparrow.lm)[2]
#
MSE = sum((sparrow$wing.length - (beta0 + beta1 * sparrow$age.days))^2)/(length(sparrow$age.days) - 2)
MSE
sparrow.newpoints = data.frame(age.days=seq(3,17))
#
sparrow.predict = predict(sparrow.lm,se.fit=T,newdata=sparrow.newpoints)
#
#
# Plot just the predictions first as points
#
plot(sparrow.newpoints$age.days, sparrow.predict$fit, pch=15)
#
plot(sparrow.newpoints$age.days, sparrow.predict$fit,type="n",
xlab="Age (days)",ylab="Predicted Wing Length (inches)")
#
lines(sparrow.newpoints$age.days, sparrow.predict$fit,lwd=3)
#
# create what is needed to make the envelope, mean +/- 2 se
sparrow.upper = sparrow.predict$fit+2*sparrow.predict$se.fit
sparrow.lower = sparrow.predict$fit-2*sparrow.predict$se.fit
lines(sparrow.newpoints$age.days, sparrow.upper, col=2, lwd=3)
lines(sparrow.newpoints$age.days, sparrow.lower, col=2, lwd=3)
#
con <- url("http://www.jhsph.edu", "r")
con
help(url)
type(con)
class(con)
x = readLines(con)
class(x)
x
con <- url("http://jhsph.edu", "r")
x = readLines(con)
head(x)
ucscDb = dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
help(dbConnect)
install.package(dbConnect)
package(dbConnect)
library(dbConnect)
library(RMySQL)
library("RMySQL")
getwd()
setwd("Desktop/OneDrive/Documents/DATA_SCIENCE")
setwd("/Desktop/OneDrive/Documents/DATA_SCIENCE")
setwd("/Desktop/OneDrive/Documents/DATA_SCIENCE/")
setwd("./Desktop/OneDrive/Documents/DATA_SCIENCE/")
setwd("Users/VeenaCalambur/Desktop/OneDrive/Documents/DATA_SCIENCE/")
install.packages("RMySQL")
library(RMySQL)
ucscDB = dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
result = dbGetQuery(ucscDB, "show databases;"); dbDisconnect(ucscDB);
result
ucscDB = dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu", db = "hg19")
allTables = dbListTables(hg19)
allTables = dbListTables(ucscDB)
length(allTables)
allTables[1:5]
dbListFields(ucscDB, "affyU133Plus2")
dbGetQuery(ucscDB, "select count(*) from affyU133Plus2")
affyData = dbReadTable (ucscDB, "affyU133Plus2")
head(affyData)
library(ElemStatLearn)
install.package(ElemStatLearn)
install.packages(ElemStatLearn)
library(ElemStatLearn)
libarary("ElemStatLearn")
library("ElemStatLearn")
install.packages("ElemStatLearn")
library("ElemStatLearn")
require(class)
x = (0,2,4, 2, 5, 6)
xposR = (0, 2, 4)
xposR = list(0, 2 4)
xposR = c(0, 2, 4)
yposR = c(1, 3, 4)
xposC = c(2, 5, 6)
yposC = c(0, 2, 3)
head(mixture.example$x)
col.names(mixture)
names(mixture)
names(mixture.example)
library(ggplot2)
qf(0.025, 64, 80)
qf(0.05, 64, 80)
If any two feature vectors are orthogonal, then we can reduce the dual optimization equation because any values of $i \neq j$ will reduce the inner product between the features to 0, And the inner product from i = j, will be the length of that particular feature, which has also been set to 1:
D(\alpha) = \sum\limits_{i = 1}^{N}\alpha_{i} - \frac{1}{2}\sum\limits_{i = 1}^{N}\sum\limits_{j = 1}^{N}y_{i}y_{j}\alpha_{i}\alpha_{j}x_{i}x_{j}
setwd("~/Desktop/CS478final/DataParsing/csv")
tdance0_1 = read.csv("dance_0to1_data.csv", header = TRUE)
tdance1_2 = read.csv("dance_1to2_data.csv", header = TRUE)
tdance2_3 = read.csv("dance_2to3_data.csv", header = TRUE)
tdance3_4 = read.csv("dance_3to4_data.csv", header = TRUE)
tdance4_5 = read.csv("dance_4to5_data.csv", header = TRUE)
tdance5_6 = read.csv("dance_5to6_data.csv", header = TRUE)
tdance6_7 = read.csv("dance_6to7_data.csv", header = TRUE)
tdance7_8 = read.csv("dance_7to8_data.csv", header = TRUE)
tdance8_9 = read.csv("dance_8to9_data.csv", header = TRUE)
tdance9_10 = read.csv("dance_9to10_data.csv", header = TRUE)
yd = merge(tdance5_6,tdance6_7,by=names(tdance0_1), all = TRUE)
yd = merge(tdance7_8,yd,by=names(tdance0_1), all = TRUE)
yd = merge(tdance8_9,yd,by=names(tdance0_1), all = TRUE)
yd = merge(tdance9_10,yd,by=names(tdance0_1), all = TRUE)
nodance = merge(tdance0_1,tdance1_2,by=names(tdance0_1), all = TRUE)
nodance = merge(tdance2_3,nodance,by=names(tdance0_1), all = TRUE)
nodance = merge(tdance3_4,nodance,by=names(tdance0_1), all = TRUE)
nodance = merge(tdance4_5,nodance,by=names(tdance0_1), all = TRUE)
dance = merge(yd, nodance, by = names(yd), all = TRUE)
attach(dance)
correlations(dance)
correlations = cor(dance)
names(dance)
correlations = cor(dance[c("key", "liveness", "tempo", "speechiness", "acousticness", "instrumentalness", "mode", "duration", "loudness", "valence", "danceability")])
correlations
#updating NA values in instrumentalness
for(i in 1:length(dance$speechiness)){
if(is.na(dance$speechiness[i])){
dance$speechiness[i] = 0.10720
}
}
for(i in 1:length(dance$instrumentalness)){
if(is.na(dance$instrumentalness[i])){
dance$instrumentalness[i] = 0.319900
}
}
correlations = cor(dance[c("key", "liveness", "tempo", "speechiness", "acousticness", "instrumentalness", "mode", "duration", "loudness", "valence", "danceability")])
correlations
correlations
plot(-3.279225e-06*valence*I(tempo^2) +  -8.160651e-04*energy*I(loudness^2) +
3.218223e-01*acousticness*I(energy^2)+-3.279225e-06*liveness*speechiness
+3.793979e-04*tempo*energy+-7.492498e-03*loudness*acousticness
+ 7.001209e-02*instrumentalness*valence+ -6.132415e-04*valence*loudness
+1.359087e-02*energy*loudness*I(valence^2), valence, pch =16)
+1.359087e-02*energy*loudness*I(valence^2), valence, pch =16, xlab = "Transformation", ylab = "Valence")
plot(-3.279225e-06*valence*I(tempo^2) +  -8.160651e-04*energy*I(loudness^2) +
3.218223e-01*acousticness*I(energy^2)+-3.279225e-06*liveness*speechiness
+3.793979e-04*tempo*energy+-7.492498e-03*loudness*acousticness
+ 7.001209e-02*instrumentalness*valence+ -6.132415e-04*valence*loudness
+1.359087e-02*energy*loudness*I(valence^2), valence, pch =16, xlab = "Transformation", ylab = "Valence")
plot(-3.279225e-06*valence*I(tempo^2) +  -8.160651e-04*energy*I(loudness^2) +
3.218223e-01*acousticness*I(energy^2)+-3.279225e-06*liveness*speechiness
+3.793979e-04*tempo*energy+-7.492498e-03*loudness*acousticness
+ 7.001209e-02*instrumentalness*valence+ -6.132415e-04*valence*loudness
+1.359087e-02*energy*loudness*I(valence^2), danceability, pch =16, xlab = "Transformation", ylab = "Danceability")
plot((-3.126570 * 10^-1)*acousticness
+  (-7.503000 * 10^-4) * tempo
+   (1.719260 * 10^-2) * loudness
+  (-1.399756 * 10^-1) * valence
+   (2.950410 * 10^-2) * danceability
+  (-2.433880 * 10^-1) * speechiness
+   (1.868210 * 10^-2) * loudness * danceability
, energy, pch = 16, xlab = "Transformation", ylab = "Valence")
summary(dem.reml)
setwd("~/Desktop/OneDrive/Documents/CORNELL/14-15/FALL/STSCI 4030")
demand = read.csv("demand.csv", header = TRUE)
dem.reml = lmer(log(DD)~(1|state)+(1|year)+PI+SC+IT+IA, data = demand)
library(lme4)
library(HLMdiag)
dem.reml = lmer(log(DD)~(1|state)+(1|year)+PI+SC+IT+IA, data = demand)
summary(dem.reml)
lmfit = lm(log(DD)~PI+SC+IT+IA, data = demand)
summary(lmfit)
setwd("~/Desktop")
setwd("~/Desktop/CS478final/DataParsing/csv")
rmse = read.csv("knnRMSE.csv", header = TRUE)
rmse = read.csv("knnRMSE.csv", header = TRUE)
rmse = read.csv("knnRMSE.csv", header = TRUE)
rmse = read.csv("knnRMSE.csv", header = TRUE)
head(rmse)
plot(x = c(1:25), y = rmse$Danceability, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates")
points(x = c(1:25), y = rmse$Danceability, col = "red", pch = 16)
lines(x = c(1:25), y = rmse$Danceability)
lines(x = c(1:25), y = rmse$Danceability, col = red)
lines(x = c(1:25), y = rmse$Danceability, col = "red")
plot(x = c(1:25), y = rmse$Danceability, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates");points(x = c(1:25), y = rmse$Danceability, col = "red", pch = 16);lines(x = c(1:25), y = rmse$Danceability, col = "red")
plot(x = c(1:25), y = rmse$Energy, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates");points(x = c(1:25), y = rmse$Energy, col = "darkolivegreen", pch = 16);lines(x = c(1:25), y = rmse$Danceability, col = "darkolivegreen")
plot(x = c(1:25), y = rmse$Danceability, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates");points(x = c(1:25), y = rmse$Danceability, col = "red", pch = 16);lines(x = c(1:25), y = rmse$Danceability, col = "red")
points(x = c(1:25), y = rmse$Energy, col = "darkolivegreen", pch = 16);lines(x = c(1:25), y = rmse$Energy, col = "darkolivegreen")
range(rmse$Danceability)
range(rmse$Energy)
range(rmse$Valence)
plot(x = c(1:25), y = rmse$Danceability, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates", ylim = c(0:0.3));points(x = c(1:25), y = rmse$Danceability, col = "red", pch = 16);lines(x = c(1:25), y = rmse$Danceability, col = "red")
plot(x = c(1:25), y = rmse$Danceability, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates", ylim = c(0,0.3));points(x = c(1:25), y = rmse$Danceability, col = "red", pch = 16);lines(x = c(1:25), y = rmse$Danceability, col = "red")
plot(x = c(1:25), y = rmse$Danceability, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates", ylim = c(0,0.24));points(x = c(1:25), y = rmse$Danceability, col = "red", pch = 16);lines(x = c(1:25), y = rmse$Danceability, col = "red")
plot(x = c(1:25), y = rmse$Danceability, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates", ylim = c(0.1,0.24));points(x = c(1:25), y = rmse$Danceability, col = "red", pch = 16);lines(x = c(1:25), y = rmse$Danceability, col = "red")
plot(x = c(1:25), y = rmse$Danceability, type = 'n', xlab = "K Number of Neighbors", ylab = "Error Rates", ylim = c(0.15,0.26));points(x = c(1:25), y = rmse$Danceability, col = "red", pch = 16);lines(x = c(1:25), y = rmse$Danceability, col = "red")
points(x = c(1:25), y = rmse$Energy, col = "darkolivegreen", pch = 16);lines(x = c(1:25), y = rmse$Energy, col = "darkolivegreen")
points(x = c(1:25), y = rmse$Valence, col = "blue", pch = 16);lines(x = c(1:25), y = rmse$Valence, col = "blue")
mean(rmse$Daneability); mean(rmse$Energy); mean(rmse$Valence)
mean(rmse$Daneability)
mean(rmse$Danceability)
mean(rmse$Valence)
mean(rmse$Energy)
legend("bottomright", c("Danceability", "Valence", "Energy"), col = c("red", "blue", "darkolivegreen"), lty = c(1,1,1), cex = 0.9)
